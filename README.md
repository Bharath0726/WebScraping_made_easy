# WebScraping_made_easy

üï∑Ô∏è Web Crawler Framework

This repository contains an asynchronous web crawler built using Python, leveraging crawl4ai for efficient web scraping. The crawler extracts content from websites, processes sitemaps, and saves the crawled data in markdown format.

Features

Asynchronous Crawling - Efficiently scrape multiple web pages concurrently using asyncio.
Sitemap Extraction - Automatically detects and processes sitemaps from a website.
Markdown Export - Saves the extracted content in markdown files for easy readability.
Retry Mechanism - Implements robust retry logic for handling failed requests.
Browser-based Crawling - Uses crawl4ai to render JavaScript-heavy pages.
Parallel Processing - Crawls multiple URLs simultaneously with configurable concurrency.
Logging & Monitoring - Logs crawl statistics, errors, and performance insights.

